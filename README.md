# 🤟 Assistive Technology for Deaf and Mute Communication

This project leverages computer vision and deep learning to **translate sign language gestures into text**, enabling real-time communication for the deaf and mute community.

---

## ✨ Features

- 📷 **Real-time gesture detection** using webcam
- 🧠 **CNN + LSTM** model to classify sign language gestures
- ⚙️ **FastAPI backend** for live stream inference
- 🐳 Containerized with Docker for easy deployment
- ☁️ Designed for low-latency cloud deployment (AWS ECS ready)

---

## 🚀 Tech Stack

| Component        | Tools Used                          |
|------------------|-------------------------------------|
| Frontend         | OpenCV, Webcam Stream               |
| Model            | PyTorch (CNN + LSTM)                |
| Backend          | FastAPI, Python                     |
| Deployment       | Docker, AWS ECS                     |

---

## 📁 Project Structure

